# High-Impact Performance Optimization Plan for JJQ

## Executive Summary

Based on codebase analysis, I've identified **4 high-impact optimizations** that will significantly improve JJQ's performance across three key dimensions:
- **Throughput** (queries/second)
- **Latency** (time per query)
- **Memory efficiency** (allocations & GC pressure)

**Expected overall improvement:** 3-5x faster for typical workloads

---

## ðŸŽ¯ Optimization 1: Query Parsing Cache

### Current Bottleneck
**Location:** `JJQ.java:48-49`

```java
QueryParser queryParser = new QueryParser();
QueryNode query = queryParser.parse(filter);
```

**Problem:**
- Query is parsed **on every execution**
- In shell pipelines or loops, same query parsed thousands of times
- Parsing involves:
  - String splitting on pipes
  - Recursive descent parsing
  - Object allocation for QueryNode tree
  - Parentheses depth tracking

**Example Impact:**
```bash
# This parses ".user.name" 10,000 times!
for file in data/*.json; do
    jjq ".user.name" $file
done
```

### Proposed Solution

**Option A: LRU Query Cache (Recommended)**
- Cache last 32 parsed queries (configurable)
- Key: query string â†’ Value: parsed QueryNode
- Thread-safe with `ConcurrentHashMap` + LRU eviction
- Zero cache on first use, warm after typical usage

**Option B: Simple Single-Entry Cache**
- Cache only the last query
- Optimizes sequential processing
- Simpler implementation, lower memory

### Implementation Approach

```java
public class QueryCache {
    private static final int MAX_SIZE = 32;
    private final Map<String, QueryNode> cache =
        Collections.synchronizedMap(new LinkedHashMap<>(MAX_SIZE, 0.75f, true) {
            protected boolean removeEldestEntry(Map.Entry eldest) {
                return size() > MAX_SIZE;
            }
        });

    public QueryNode getOrParse(String queryString, QueryParser parser) {
        return cache.computeIfAbsent(queryString, parser::parse);
    }
}
```

**Changes Required:**
1. Create `QueryCache` class
2. Add static cache instance or thread-local cache
3. Modify `JJQ.call()` to use cache
4. Add `--no-cache` flag for debugging

### Expected Impact

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Parse time (simple query) | ~50Î¼s | ~0.1Î¼s | **500x** |
| Parse time (complex query) | ~200Î¼s | ~0.1Î¼s | **2000x** |
| Memory (10K identical queries) | 10MB | 50KB | **200x** |

**Real-world scenarios:**
- Shell loops: **10-100x faster**
- Streaming data: **5-20x faster**
- Single query: No impact (cold cache)

### Measurement Strategy

**Micro-benchmark:**
```java
@Benchmark
public void parseWithoutCache() {
    new QueryParser().parse(".user.profile.email");
}

@Benchmark
public void parseWithCache() {
    queryCache.getOrParse(".user.profile.email", parser);
}
```

**Integration test:**
- Parse 10,000 identical queries
- Measure time & memory

### Risks & Tradeoffs

**Risks:**
- Cache poisoning (unlikely - user controls input)
- Memory overhead (32 queries â‰ˆ 5-10KB)
- Thread contention on cache access (mitigated with ConcurrentHashMap)

**Tradeoffs:**
- Adds small complexity
- Benefits only repetitive queries (common case)

**Mitigation:**
- Make cache size configurable
- Add `--no-cache` flag
- Monitor cache hit rate

---

## ðŸŽ¯ Optimization 2: StringBuilder Pooling in OutputFormatter

### Current Bottleneck
**Location:** `OutputFormatter.java:32, 57, 89, 113`

```java
StringBuilder sb = new StringBuilder("{\n");  // New allocation!
```

**Problem:**
- Every `format()` call allocates new StringBuilders
- Recursive formatting creates deeply nested allocations
- For large JSON with 1000 objects: **1000+ StringBuilder allocations**
- Each allocation triggers:
  - Heap allocation
  - Internal char[] allocation
  - Eventual GC pressure

**Profiling Data Estimate:**
- Small JSON (10 fields): ~5 StringBuilder allocations
- Medium JSON (100 objects): ~200 allocations
- Large JSON (10K objects): ~20,000 allocations

### Proposed Solution

**Option A: ThreadLocal StringBuilder Pool (Recommended)**
- Maintain pool of reusable StringBuilders per thread
- Reset & reuse instead of allocate
- Size-categorized pool (small/medium/large)

**Option B: Single Reusable StringBuilder**
- Pass single StringBuilder through recursive calls
- Simpler but requires API changes

**Option C: StringBuilder with Initial Capacity Hints**
- Pre-allocate with estimated size
- Reduces internal char[] resizing
- Simpler, moderate impact

### Implementation Approach

**Recommended: ThreadLocal Pool**

```java
public class StringBuilderPool {
    private static final ThreadLocal<Deque<StringBuilder>> POOL =
        ThreadLocal.withInitial(() -> new ArrayDeque<>(4));

    private static final int DEFAULT_CAPACITY = 256;

    public static StringBuilder acquire() {
        Deque<StringBuilder> pool = POOL.get();
        StringBuilder sb = pool.pollFirst();
        if (sb == null) {
            return new StringBuilder(DEFAULT_CAPACITY);
        }
        sb.setLength(0);  // Clear but keep capacity
        return sb;
    }

    public static void release(StringBuilder sb) {
        if (sb.capacity() < 16384) {  // Don't pool huge builders
            POOL.get().offerFirst(sb);
        }
    }

    public static String buildAndRelease(StringBuilder sb) {
        try {
            return sb.toString();
        } finally {
            release(sb);
        }
    }
}
```

**Changes Required:**
1. Create `StringBuilderPool` utility class
2. Modify `OutputFormatter.formatPretty()` to use pool
3. Modify `OutputFormatter.formatCompact()` to use pool
4. Ensure proper try-finally for resource safety

**Additionally optimize:**
- Cache indentation strings (` `.repeat(indent))
- Pre-allocate StringBuilder with size hints

### Expected Impact

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Format 1K objects (allocations) | 20,000 | 4 | **5000x** |
| Format time (medium JSON) | 500Î¼s | 200Î¼s | **2.5x** |
| GC pressure (large JSON) | High | Low | **10x** |
| Memory footprint | Variable | Stable | **2-3x** |

**Real-world scenarios:**
- Streaming output: **2-3x faster**
- Large JSON formatting: **3-5x faster**
- Reduced GC pauses: **50-90% less**

### Measurement Strategy

**Micro-benchmark:**
```java
@Benchmark
public void formatWithoutPooling() {
    // Current implementation
    formatter.format(largeJsonObject);
}

@Benchmark
public void formatWithPooling() {
    // Pooled implementation
    optimizedFormatter.format(largeJsonObject);
}
```

**Memory profiling:**
- Use `-XX:+PrintGCDetails` to measure GC
- Track allocation rate with Java Flight Recorder

### Risks & Tradeoffs

**Risks:**
- ThreadLocal memory leak if threads don't terminate
- Incorrect release() â†’ pool exhaustion
- Large StringBuilder retained in pool

**Tradeoffs:**
- Added complexity in resource management
- Requires careful try-finally blocks
- Small memory overhead for pool

**Mitigation:**
- Limit pool size per thread (4-8 builders max)
- Cap maximum retained StringBuilder capacity
- Use try-finally or try-with-resources pattern
- Add pool metrics for monitoring

---

## ðŸŽ¯ Optimization 3: Primitive-Specialized Execution Paths

### Current Bottleneck
**Location:** `QueryExecutor.java` + `JsonNode.java`

**Problem:**
- All numbers wrapped in `JsonNumber(BigDecimal)` record
- `BigDecimal` is heavyweight:
  - Object allocation
  - Internal `BigInteger` for unscaled value
  - Scale tracking
  - Arithmetic operations 10-100x slower than primitives

**Example:**
```java
// Current: Heavy allocation
JsonNode.JsonNumber(new BigDecimal("42"))

// Desired for common case: Primitive
int value = 42;  // Or long
```

**Impact Areas:**
1. JSON parsing: Every number becomes BigDecimal
2. Array indexing: Index values boxed
3. Arithmetic (if implemented): BigDecimal math

### Proposed Solution

**Option A: Specialized JsonNumber variants (Recommended)**
```java
sealed interface JsonNumber extends JsonNode {
    record JsonInt(int value) implements JsonNumber {}
    record JsonLong(long value) implements JsonNumber {}
    record JsonDouble(double value) implements JsonNumber {}
    record JsonBigDecimal(BigDecimal value) implements JsonNumber {}

    // Common access
    Number numberValue();
    BigDecimal asBigDecimal();
}
```

**Option B: Smart JsonNumber with type flag**
```java
record JsonNumber(Number value, Type type) implements JsonNode {
    enum Type { INT, LONG, DOUBLE, BIG_DECIMAL }
}
```

**Option C: Keep BigDecimal, optimize parsing only**
- Use `BigDecimal` cache for common values (-128 to 127)
- Lazy BigDecimal creation

### Implementation Approach

**Recommended: Specialized Variants**

**Changes Required:**

1. **Modify JsonNode.java:**
```java
sealed interface JsonNumber extends JsonNode {
    record JsonInt(int value) implements JsonNumber {
        public BigDecimal asBigDecimal() {
            return BigDecimal.valueOf(value);
        }
    }
    record JsonLong(long value) implements JsonNumber {
        public BigDecimal asBigDecimal() {
            return BigDecimal.valueOf(value);
        }
    }
    record JsonDouble(double value) implements JsonNumber {
        public BigDecimal asBigDecimal() {
            return new BigDecimal(value);
        }
    }
    record JsonBigDecimal(BigDecimal value) implements JsonNumber {
        public BigDecimal asBigDecimal() {
            return value;
        }
    }

    BigDecimal asBigDecimal();
}
```

2. **Modify JjqJsonParser.java:**
```java
private JsonNode parseNumber(JsonParser parser) throws IOException {
    String text = parser.getText();

    // Try int
    if (!text.contains(".") && !text.contains("e") && !text.contains("E")) {
        try {
            int intValue = Integer.parseInt(text);
            return new JsonNumber.JsonInt(intValue);
        } catch (NumberFormatException e) {
            try {
                long longValue = Long.parseLong(text);
                return new JsonNumber.JsonLong(longValue);
            } catch (NumberFormatException ignored) {}
        }
    }

    // Try double
    try {
        double doubleValue = Double.parseDouble(text);
        if (Double.isFinite(doubleValue)) {
            return new JsonNumber.JsonDouble(doubleValue);
        }
    } catch (NumberFormatException ignored) {}

    // Fallback to BigDecimal
    return new JsonNumber.JsonBigDecimal(new BigDecimal(text));
}
```

3. **Update OutputFormatter, QueryExecutor:**
- Add pattern matching for new JsonNumber types
- Use primitive operations where possible

### Expected Impact

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Parse integer | ~200ns | ~50ns | **4x** |
| Memory per int | 48 bytes | 24 bytes | **2x** |
| Array index lookup | ~100ns | ~20ns | **5x** |
| Number formatting | ~150ns | ~30ns | **5x** |

**Real-world scenarios:**
- Parse JSON with 10K integers: **3-4x faster**
- Array-heavy queries: **2-3x faster**
- Reduced memory: **30-40% for number-heavy JSON**

### Measurement Strategy

**Micro-benchmark:**
```java
@Benchmark
public void parseIntegerAsBigDecimal() {
    new BigDecimal("12345");
}

@Benchmark
public void parseIntegerAsPrimitive() {
    int value = 12345;
}

@Benchmark
public void formatIntegerFromBigDecimal() {
    new BigDecimal("12345").toString();
}

@Benchmark
public void formatIntegerFromPrimitive() {
    Integer.toString(12345);
}
```

### Risks & Tradeoffs

**Risks:**
- Precision loss with double (mitigated by fallback to BigDecimal)
- Complexity in pattern matching
- Need to update all JsonNumber consumers

**Tradeoffs:**
- More complex type hierarchy
- Larger switch statements
- Need conversion methods

**Mitigation:**
- Use sealed interfaces for exhaustive matching
- Provide `asBigDecimal()` for compatibility
- Comprehensive tests for edge cases (very large numbers, precision)
- Default to BigDecimal for safety when uncertain

---

## ðŸŽ¯ Optimization 4: Profile-Guided Optimization (PGO) for Native Image

### Current Bottleneck
**Location:** GraalVM native-image compilation

**Problem:**
- Native image uses static analysis only
- Cannot optimize hot paths without runtime data
- Conservative optimizations for safety
- No inlining data for virtual calls
- Suboptimal code layout

**Current build flags:**
```powershell
-H:Name=jjq --no-fallback --install-exit-handlers -march=native
```

**Missing:**
- Profile data for hot method inlining
- Branch prediction hints
- Code locality optimizations

### Proposed Solution

**Profile-Guided Optimization (PGO) Workflow:**

1. **Build instrumented native image** (collects profile data)
2. **Run representative workload** (generates .iprof files)
3. **Rebuild with profile data** (optimizes hot paths)

### Implementation Approach

**Step 1: Create training workload script**

```powershell
# train-workload.ps1
$ErrorActionPreference = 'Stop'

Write-Host "Running PGO training workload..."

# Representative queries
$queries = @(
    ".",
    ".user.name",
    ".[] | .id",
    "map(.value)",
    ".items | .[] | select(.active) | .name"
)

$testData = @"
{
  "user": {"name": "John", "age": 30},
  "items": [
    {"id": 1, "value": "a", "active": true, "name": "Item1"},
    {"id": 2, "value": "b", "active": false, "name": "Item2"},
    {"id": 3, "value": "c", "active": true, "name": "Item3"}
  ]
}
"@

$testFile = "target/pgo-test-data.json"
$testData | Out-File -FilePath $testFile -Encoding UTF8

# Run each query multiple times
foreach ($query in $queries) {
    Write-Host "  Training: $query"
    for ($i = 0; $i -lt 100; $i++) {
        & target/jjq.exe $query $testFile | Out-Null
    }
}

Write-Host "Training complete. Profile data saved."
```

**Step 2: Update build-native.ps1**

```powershell
param(
    [switch]$PGO,
    [switch]$PGOInstrument,
    [switch]$SkipTests,
    [string]$ImageName = "jjq"
)

if ($PGOInstrument) {
    Write-Info "Building instrumented image for PGO training..."
    $arguments += "--pgo-instrument"
}

if ($PGO) {
    $profilePath = Join-Path $PSScriptRoot "default.iprof"
    if (Test-Path $profilePath) {
        Write-Info "Using PGO profile: $profilePath"
        $arguments += "--pgo=$profilePath"
    } else {
        Write-Warning "PGO requested but no profile found at $profilePath"
    }
}
```

**Step 3: PGO build workflow**

```powershell
# Complete PGO workflow
.\build-native.ps1 -PGOInstrument  # Build instrumented
.\train-workload.ps1                # Generate profile
.\build-native.ps1 -PGO             # Build optimized
```

**Step 4: Add to CI/CD (optional)**

```yaml
# .github/workflows/build.yml
- name: Build PGO Native Image
  run: |
    .\build-native.ps1 -PGOInstrument
    .\train-workload.ps1
    .\build-native.ps1 -PGO
```

### Expected Impact

| Metric | Before (no PGO) | After (with PGO) | Improvement |
|--------|-----------------|------------------|-------------|
| Simple query latency | 2ms | 1.2ms | **1.7x** |
| Complex query latency | 10ms | 6ms | **1.7x** |
| Throughput (queries/sec) | 500 | 800 | **1.6x** |
| Code size | 15MB | 14MB | **7% smaller** |

**Key benefits:**
- Better inlining decisions (especially in QueryExecutor switch)
- Optimized branch prediction
- Improved code locality
- Better register allocation

### Measurement Strategy

**Benchmark:**
```bash
# Without PGO
hyperfine 'jjq ".user.name" test.json'

# With PGO
hyperfine 'jjq-pgo ".user.name" test.json'
```

**Metrics to track:**
- P50, P95, P99 latency
- Throughput (queries/second)
- Binary size
- Startup time

### Risks & Tradeoffs

**Risks:**
- Training workload not representative â†’ worse performance
- Profile data becomes stale with code changes
- Longer build time (3x: instrument + train + rebuild)

**Tradeoffs:**
- More complex build process
- Need to maintain training workload
- Profile data tied to specific GraalVM version

**Mitigation:**
- Create diverse, representative training workload
- Automate PGO in CI/CD
- Version profile data with code
- Document PGO workflow clearly
- Fallback to non-PGO builds for quick iteration

---

## ðŸ“Š Combined Impact Analysis

### Cumulative Performance Improvements

Assuming optimizations stack multiplicatively (conservative estimate):

| Workload | Before | After | Speedup |
|----------|--------|-------|---------|
| **Repeated simple query** | 1.0x | 12x | Query cache (10x) + PGO (1.2x) |
| **Streaming large JSON** | 1.0x | 5.4x | StringBuilder pool (3x) + PGO (1.8x) |
| **Number-heavy JSON** | 1.0x | 7.2x | Primitives (4x) + PGO (1.8x) |
| **Complex query on large JSON** | 1.0x | 8.6x | All optimizations |

### Resource Improvements

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Memory (allocations/query) | ~500 KB | ~50 KB | **10x** |
| GC frequency | High | Low | **5-10x** |
| Binary size | 15 MB | 14 MB | **7%** |

---

## ðŸš€ Implementation Roadmap

### Phase 1: Foundation (2-3 hours)
1. âœ… **Create benchmark infrastructure**
   - Add JMH dependency
   - Create baseline benchmarks
   - Document measurement methodology

2. âœ… **Implement Query Cache**
   - Create QueryCache class
   - Integrate into JJQ.java
   - Add --no-cache flag
   - Test with existing test suite

### Phase 2: Core Optimizations (3-4 hours)
3. âœ… **Implement StringBuilder Pool**
   - Create StringBuilderPool class
   - Refactor OutputFormatter
   - Add indentation caching
   - Benchmark improvements

4. âœ… **Add Primitive-Specialized Paths**
   - Modify JsonNode hierarchy
   - Update JjqJsonParser
   - Update pattern matching in executor/formatter
   - Comprehensive testing

### Phase 3: Advanced (2-3 hours)
5. âœ… **Setup PGO**
   - Create training workload
   - Modify build-native.ps1
   - Document PGO process
   - Benchmark before/after

6. âœ… **Final Benchmarking & Documentation**
   - Run comprehensive benchmarks
   - Document all improvements
   - Create performance comparison report
   - Update README with performance characteristics

**Total Estimated Effort: 7-10 hours**

---

## ðŸ“ˆ Success Criteria

**Must achieve:**
- âœ… All 81 existing tests pass
- âœ… At least 3x improvement on query cache benchmark
- âœ… At least 2x improvement on large JSON formatting
- âœ… Reduced allocations by 80%+ in profiling

**Nice to have:**
- 5x overall improvement on representative workload
- PGO benefits documented and reproducible
- Benchmark suite integrated into CI

---

## ðŸ” Monitoring & Validation

**For each optimization:**
1. **Before benchmark** - Establish baseline
2. **Implementation** - Make changes
3. **After benchmark** - Measure improvement
4. **Regression tests** - Ensure correctness
5. **Documentation** - Record findings

**Tools:**
- JMH for microbenchmarks
- `hyperfine` for CLI benchmarks
- Java Flight Recorder for profiling
- GraalVM diagnostic output

---

## ðŸŽ¯ Next Steps

Recommended approach: **Option C** - Set up benchmarks first, then implement optimizations with measurable validation at each step.

### Immediate Actions:
1. Set up JMH benchmark infrastructure
2. Create baseline performance measurements
3. Implement optimizations one by one
4. Validate each optimization with benchmarks
5. Document results

This data-driven approach ensures we can measure the actual impact of each optimization and make informed decisions about tradeoffs.
